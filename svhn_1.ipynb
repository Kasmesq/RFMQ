{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0380a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e89e0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import rfm_q\n",
    "importlib.reload(rfm_q)  # Reload the updated module\n",
    "from rfm_q import q_rfm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2da1e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AerSimulator('aer_simulator'), AerSimulator('aer_simulator_statevector'), AerSimulator('aer_simulator_density_matrix'), AerSimulator('aer_simulator_stabilizer'), AerSimulator('aer_simulator_matrix_product_state'), AerSimulator('aer_simulator_extended_stabilizer'), AerSimulator('aer_simulator_unitary'), AerSimulator('aer_simulator_superop'), QasmSimulator('qasm_simulator'), StatevectorSimulator('statevector_simulator'), UnitarySimulator('unitary_simulator')]\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import Aer\n",
    "print(Aer.backends())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "778ae8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d805a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path\n",
    "def set_data_path():\n",
    "    return \"../data/\"\n",
    "#     raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9169089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(torchset,n_samples,num_classes=10):\n",
    "    indices = list(np.random.choice(len(torchset),n_samples))\n",
    "\n",
    "    trainset = []\n",
    "    for ix in indices:\n",
    "        x,y = torchset[ix]\n",
    "        ohe_y = torch.zeros(num_classes)\n",
    "        ohe_y[y] = 1\n",
    "        trainset.append(((x/np.linalg.norm(x)).reshape(-1),ohe_y))\n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "777dbd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/train_32x32.mat\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# load svhn data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_path = set_data_path() ## set this data path\n",
    "\n",
    "trainset0 = torchvision.datasets.SVHN(root=data_path,\n",
    "                                    split = \"train\",\n",
    "                                    transform=transform,\n",
    "                                    download=True)\n",
    "testset0 = torchvision.datasets.SVHN(root=data_path,\n",
    "                                    split = \"test\",\n",
    "                                    transform=transform,\n",
    "                                    download=True)\n",
    "\n",
    "trainset = pre_process(trainset0,n_samples=5000, num_classes=10)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testset = pre_process(testset0,n_samples=5000, num_classes=10)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e7f0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfm import \n",
    "from rfm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ded7fbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit-aer in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (0.16.4)\n",
      "Requirement already satisfied: qiskit>=1.1.0 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit-aer) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit-aer) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit-aer) (1.10.1)\n",
      "Requirement already satisfied: psutil>=5 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit-aer) (6.0.0)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit>=1.1.0->qiskit-aer) (0.15.1)\n",
      "Requirement already satisfied: sympy>=1.3 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit>=1.1.0->qiskit-aer) (1.13.3)\n",
      "Requirement already satisfied: dill>=0.3 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit>=1.1.0->qiskit-aer) (2.9.0)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit>=1.1.0->qiskit-aer) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit>=1.1.0->qiskit-aer) (4.12.2)\n",
      "Requirement already satisfied: symengine<0.14,>=0.11 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from qiskit>=1.1.0->qiskit-aer) (0.13.0)\n",
      "Requirement already satisfied: six>=1.5 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from python-dateutil>=2.8.0->qiskit>=1.1.0->qiskit-aer) (1.16.0)\n",
      "Requirement already satisfied: pbr>=2.0.0 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from sympy>=1.3->qiskit>=1.1.0->qiskit-aer) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /data/yi/miniconda3/envs/rfm_env/lib/python3.8/site-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (75.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit-aer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "127833ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import rfm_q\n",
    "importlib.reload(rfm_q)\n",
    "from rfm_q import q_rfm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9bedd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706e7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from scipy.io import loadmat\n",
    "# from sklearn.decomposition import PCA\n",
    "# ##########################\n",
    "# # 1) Load the .mat files  #\n",
    "# ###########################\n",
    "\n",
    "# train_mat_path = \"/data/yi/recursive_feature_machines_1/data/train_32x32.mat\"\n",
    "# test_mat_path  = \"/data/yi/recursive_feature_machines_1/data/test_32x32.mat\"\n",
    "\n",
    "# train_data = loadmat(train_mat_path)\n",
    "# test_data  = loadmat(test_mat_path)\n",
    "\n",
    "# # For an SVHN-like dataset:\n",
    "# #   X has shape (height=32, width=32, channels=3, N=number_of_samples)\n",
    "# #   y has shape (N,1)\n",
    "# X_train = train_data[\"X\"]  # shape (32, 32, 3, N)\n",
    "# y_train = train_data[\"y\"]  # shape (N, 1)\n",
    "# X_test  = test_data[\"X\"]   # shape (32, 32, 3, N)\n",
    "# y_test  = test_data[\"y\"]   # shape (N, 1)\n",
    "\n",
    "# print(\"Original X_train shape:\", X_train.shape)  # e.g. (32,32,3,N)\n",
    "# print(\"Original y_train shape:\", y_train.shape)  # e.g. (N,1)\n",
    "\n",
    "# ###########################\n",
    "# # 2) Reshape / Transpose  #\n",
    "# ###########################\n",
    "\n",
    "# # Transpose X from [H,W,C,N] -> [N,C,H,W] so it matches PyTorch's [N, C, H, W] format\n",
    "# X_train = np.transpose(X_train, (3, 2, 0, 1))  # shape now [N, 3, 32, 32]\n",
    "# X_test  = np.transpose(X_test,  (3, 2, 0, 1))  # shape now [N, 3, 32, 32]\n",
    "\n",
    "# # Flatten y from [N,1] -> [N]\n",
    "# y_train = y_train.flatten()\n",
    "# y_test  = y_test.flatten()\n",
    "\n",
    "# print(\"After transpose, X_train shape:\", X_train.shape)  # e.g. (N, 3, 32, 32)\n",
    "# print(\"After flatten, y_train shape:\", y_train.shape)    # e.g. (N,)\n",
    "\n",
    "# ##############################\n",
    "# # 3) Flatten for PCA (Optional)\n",
    "# ##############################\n",
    "\n",
    "# def flatten_dataset(X, y):\n",
    "#     \"\"\"\n",
    "#     Flatten images from [N, C, H, W] -> [N, C*H*W].\n",
    "#     Returns X_flat, y (unchanged).\n",
    "#     \"\"\"\n",
    "#     N, C, H, W = X.shape\n",
    "#     X_flat = X.reshape(N, -1)  # shape [N, 3*32*32=3072] if 3-channel\n",
    "#     return X_flat, y\n",
    "\n",
    "# X_train_flat, y_train = flatten_dataset(X_train, y_train)\n",
    "# X_test_flat,  y_test  = flatten_dataset(X_test,  y_test)\n",
    "\n",
    "# ##############################\n",
    "# # 4) Apply PCA (Optional)    #\n",
    "# ##############################\n",
    "\n",
    "# def reduce_dimensionality(X, n_components=8):\n",
    "#     pca = PCA(n_components=n_components)\n",
    "#     return pca.fit_transform(X)\n",
    "\n",
    "# # From 3072 -> 8 dims, for example\n",
    "# X_train_pca = reduce_dimensionality(X_train_flat, n_components=8)\n",
    "# X_test_pca  = reduce_dimensionality(X_test_flat,  n_components=8)\n",
    "\n",
    "# print(\"X_train_pca shape:\", X_train_pca.shape)  # e.g. [N, 8]\n",
    "# print(\"y_train shape:\", y_train.shape)          # e.g. [N]\n",
    "\n",
    "# ##############################\n",
    "# # 5) Wrap in DataLoaders     #\n",
    "# ##############################\n",
    "\n",
    "# # Convert NumPy arrays to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train,       dtype=torch.long)\n",
    "# X_test_tensor  = torch.tensor(X_test_pca,    dtype=torch.float32)\n",
    "# y_test_tensor  = torch.tensor(y_test,        dtype=torch.long)\n",
    "\n",
    "# # Create TensorDatasets\n",
    "# train_pca_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_pca_dataset  = TensorDataset(X_test_tensor,  y_test_tensor)\n",
    "\n",
    "# # Finally create DataLoaders\n",
    "# train_pca_loader = DataLoader(train_pca_dataset, batch_size=128, shuffle=True)\n",
    "# test_pca_loader  = DataLoader(test_pca_dataset,  batch_size=128, shuffle=False)\n",
    "\n",
    "# ##############################\n",
    "# # 6) Use these in your RFM   #\n",
    "# ##############################\n",
    "\n",
    "# # Now you can call your quantum RFM function:\n",
    "# # from rfm_q import q_rfm\n",
    "# # M, mse = q_rfm(train_pca_loader, test_pca_loader, iters=2, loader=True, classif=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e103fbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Evaluating quantum kernel fidelity matrix...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (10, 5), time 0.71 s\n",
      "[DEBUG] Quantum distance matrix computed (1 - fidelity).\n",
      "[DEBUG] Applying Laplacian transformation with gamma = 1.0000...\n",
      "[DEBUG] Laplacian quantum kernel matrix computed.\n",
      "Laplacian Quantum Kernel Matrix (Dummy Data):\n",
      " [[0.36815895 0.37313502 0.37052284 0.3744439  0.37221816]\n",
      " [0.36910162 0.36822857 0.36877155 0.36956059 0.36840771]\n",
      " [0.37334294 0.36935135 0.36900308 0.36888126 0.38118131]\n",
      " [0.3680208  0.37102013 0.3685181  0.37123795 0.36901149]\n",
      " [0.36874256 0.37191494 0.37253554 0.36940608 0.36983414]\n",
      " [0.36813563 0.37168031 0.3702018  0.36966791 0.36830368]\n",
      " [0.37181372 0.37609747 0.37077498 0.36997134 0.37533182]\n",
      " [0.37014749 0.3723179  0.36997881 0.36875583 0.36861336]\n",
      " [0.36912481 0.36882297 0.36790315 0.36834884 0.38690327]\n",
      " [0.36942903 0.36828568 0.37166452 0.36945387 0.36822303]]\n",
      "[DEBUG] Evaluating quantum kernel fidelity matrix...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 365\u001b[0m\n\u001b[1;32m    361\u001b[0m M \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Example: Compute a Laplacian quantum kernel using X_train as both samples and centers.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# (Using y_train as centers is not valid since they are labels.)\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m K_lap_mat \u001b[38;5;241m=\u001b[39m \u001b[43mquantum_laplacian_M\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbandwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_encode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaplacian Quantum Kernel Matrix (MAT Data):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, K_lap_mat)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# Optionally, run the quantum RFM.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# (Uncomment the following two lines if you wish to run q_rfm.)\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# M_final, mse = q_rfm(samples, centers, iters=2, loader=True, classif=True)\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# print(\"Final MSE from q_rfm on .mat data:\", mse)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 264\u001b[0m, in \u001b[0;36mquantum_laplacian_M\u001b[0;34m(samples, centers, bandwidth, M, q_kernel, do_encode)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m bandwidth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBandwidth must be greater than 0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Evaluating quantum kernel fidelity matrix...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 264\u001b[0m kernel_mat \u001b[38;5;241m=\u001b[39m \u001b[43mquantum_kernel_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_encode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_encode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m q_kernel \u001b[38;5;241m=\u001b[39m FidelityQuantumKernel(feature_map\u001b[38;5;241m=\u001b[39mfeature_map, enforce_psd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, max_circuits_per_job\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Convert fidelity to a quantum distance (1 - fidelity)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 236\u001b[0m, in \u001b[0;36mquantum_kernel_matrix\u001b[0;34m(X1, X2, q_kernel, M, do_encode)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Evaluating Quantum Kernel...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 236\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43mq_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Kernel evaluated: shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, time \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rfm_env/lib/python3.8/site-packages/qiskit_machine_learning/kernels/fidelity_quantum_kernel.py:113\u001b[0m, in \u001b[0;36mFidelityQuantumKernel.evaluate\u001b[0;34m(self, x_vec, y_vec)\u001b[0m\n\u001b[1;32m    110\u001b[0m kernel_shape \u001b[38;5;241m=\u001b[39m (x_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], y_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_symmetric:\n\u001b[0;32m--> 113\u001b[0m     left_parameters, right_parameters, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_symmetric_parameterization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_symmetric_kernel_matrix(\n\u001b[1;32m    115\u001b[0m         kernel_shape, left_parameters, right_parameters, indices\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rfm_env/lib/python3.8/site-packages/qiskit_machine_learning/kernels/fidelity_quantum_kernel.py:166\u001b[0m, in \u001b[0;36mFidelityQuantumKernel._get_symmetric_parameterization\u001b[0;34m(self, x_vec)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_trivial(i, i \u001b[38;5;241m+\u001b[39m j, x_i, x_j, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m left_parameters \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m right_parameters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((right_parameters, x_j))\n\u001b[1;32m    168\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend((i, i \u001b[38;5;241m+\u001b[39m j))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/rfm_env/lib/python3.8/site-packages/numpy/core/shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # %% [code]\n",
    "# # --- Section 1: Laplacian Quantum Kernel with Dummy Data ---\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import time\n",
    "\n",
    "# # Qiskit imports\n",
    "# from qiskit.circuit.library import ZZFeatureMap\n",
    "# from qiskit_aer import Aer\n",
    "# from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# # -------------------------------\n",
    "# # Helper Functions Definitions\n",
    "# # -------------------------------\n",
    "\n",
    "# def encode_features(X):\n",
    "#     \"\"\"\n",
    "#     Scales each column of X to [0, 1] then multiplies by pi.\n",
    "#     \"\"\"\n",
    "#     X = X.copy()\n",
    "#     for j in range(X.shape[1]):\n",
    "#         col_min = X[:, j].min()\n",
    "#         col_max = X[:, j].max()\n",
    "#         if abs(col_max - col_min) < 1e-12:\n",
    "#             X[:, j] = 0.0\n",
    "#         else:\n",
    "#             X[:, j] = (X[:, j] - col_min) / (col_max - col_min)\n",
    "#     X *= np.pi\n",
    "#     return X\n",
    "\n",
    "# def quantum_kernel_matrix(X1, X2, q_kernel, M=None, do_encode=True):\n",
    "#     \"\"\"\n",
    "#     Evaluates the quantum kernel matrix for inputs X1 and X2.\n",
    "#     Applies optional encoding (scaling) and a linear transformation via M.\n",
    "#     \"\"\"\n",
    "#     # Convert torch.Tensor to NumPy arrays if needed.\n",
    "#     if isinstance(X1, torch.Tensor):\n",
    "#         X1 = X1.cpu().numpy()\n",
    "#     if isinstance(X2, torch.Tensor):\n",
    "#         X2 = X2.cpu().numpy()\n",
    "\n",
    "#     # Optional encoding: scale data from [0,1] to [0,pi]\n",
    "#     if do_encode:\n",
    "#         X1 = encode_features(X1)\n",
    "#         X2 = encode_features(X2)\n",
    "\n",
    "#     # If M is provided, transform the data via its Cholesky factorization.\n",
    "#     if M is not None:\n",
    "#         sqrtM = np.real_if_close(np.linalg.cholesky(M))\n",
    "#         X1 = X1 @ sqrtM\n",
    "#         X2 = X2 @ sqrtM\n",
    "\n",
    "#     print(\"[DEBUG] Evaluating Quantum Kernel...\")\n",
    "#     start_time = time.time()\n",
    "#     K = q_kernel.evaluate(x_vec=X1, y_vec=X2)\n",
    "#     end_time = time.time()\n",
    "#     print(f\"[DEBUG] Kernel evaluated: shape {K.shape}, time {end_time - start_time:.2f} s\")\n",
    "#     return K\n",
    "\n",
    "# def quantum_laplacian_M(samples, centers, bandwidth, M, q_kernel, do_encode=True):\n",
    "#     \"\"\"\n",
    "#     Computes a Laplacian-style quantum kernel matrix.\n",
    "    \n",
    "#     The quantum kernel is first evaluated (using q_kernel with the M-transformation),\n",
    "#     then converted into a distance measure (1 - fidelity), and finally transformed via:\n",
    "#         k(x,y) = exp(-gamma * distance(x,y))\n",
    "#     where gamma = 1/bandwidth.\n",
    "    \n",
    "#     Args:\n",
    "#         samples (np.ndarray or torch.Tensor): Input data samples.\n",
    "#         centers (np.ndarray or torch.Tensor): Center points.\n",
    "#         bandwidth (float): Bandwidth parameter (must be > 0).\n",
    "#         M (np.ndarray): Transformation matrix.\n",
    "#         q_kernel: A quantum kernel instance (e.g., FidelityQuantumKernel).\n",
    "#         do_encode (bool): Whether to encode features (scaling to [0,pi]).\n",
    "    \n",
    "#     Returns:\n",
    "#         np.ndarray: Laplacian quantum kernel matrix.\n",
    "#     \"\"\"\n",
    "#     assert bandwidth > 0, \"Bandwidth must be greater than 0.\"\n",
    "    \n",
    "#     print(\"[DEBUG] Evaluating quantum kernel fidelity matrix...\")\n",
    "#     kernel_mat = quantum_kernel_matrix(samples, centers, q_kernel, M=M, do_encode=do_encode)\n",
    "    \n",
    "#     # Convert fidelity to a quantum distance (1 - fidelity)\n",
    "#     quantum_distance = 1 - kernel_mat\n",
    "#     quantum_distance = np.maximum(quantum_distance, 0)  # ensure non-negative\n",
    "#     print(\"[DEBUG] Quantum distance matrix computed (1 - fidelity).\")\n",
    "    \n",
    "#     # Apply Laplacian transformation\n",
    "#     gamma = 1.0 / bandwidth\n",
    "#     print(f\"[DEBUG] Applying Laplacian transformation with gamma = {gamma:.4f}...\")\n",
    "#     laplacian_kernel = np.exp(-gamma * quantum_distance)\n",
    "#     print(\"[DEBUG] Laplacian quantum kernel matrix computed.\")\n",
    "#     return laplacian_kernel\n",
    "\n",
    "# # -------------------------------\n",
    "# # Dummy Data Demonstration\n",
    "# # -------------------------------\n",
    "\n",
    "# # Generate dummy data\n",
    "# np.random.seed(0)\n",
    "# samples = np.random.rand(10, 8)    # 10 samples, 8 features\n",
    "# centers = np.random.rand(5, 8)     # 5 centers, 8 features\n",
    "# bandwidth = 1.0\n",
    "# M = np.eye(8, dtype='float32')     # Identity matrix for transformation\n",
    "\n",
    "# # Set up the quantum kernel using Qiskit's FidelityQuantumKernel.\n",
    "# feature_dim = 8  # Must match the data feature dimension\n",
    "# feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement=\"full\")\n",
    "# backend = Aer.get_backend(\"aer_simulator_statevector\")\n",
    "# # Disable PSD enforcement to speed up evaluation.\n",
    "# q_kernel = FidelityQuantumKernel(feature_map=feature_map, enforce_psd=False)\n",
    "\n",
    "# # Compute the Laplacian quantum kernel matrix with dummy data.\n",
    "# K_lap = quantum_laplacian_M(samples, centers, bandwidth, M, q_kernel, do_encode=True)\n",
    "# print(\"Laplacian Quantum Kernel Matrix (Dummy Data):\\n\", K_lap)\n",
    "\n",
    "\n",
    "# # %% [code]\n",
    "# # --- Section 2: Running q_rfm with Your .mat Data ---\n",
    "# #\n",
    "# # Assumptions:\n",
    "# #   - Your training and testing data are stored in 'train_data.mat' and 'test_data.mat'\n",
    "# #   - The .mat files contain:\n",
    "# #         X: shape (32, 32, 3, N)   (images)\n",
    "# #         y: shape (N, 1)           (labels)\n",
    "# #\n",
    "# # This section loads the data, preprocesses it (flattening images),\n",
    "# # and creates PyTorch DataLoaders to run the quantum RFM.\n",
    "\n",
    "# import scipy.io\n",
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# # Import the q_rfm and get_data functions from your module.\n",
    "# from rfm_q import q_rfm, get_data\n",
    "\n",
    "# # Load your .mat files.\n",
    "# train_data = scipy.io.loadmat('/data/yi/recursive_feature_machines_1/data/train_32x32.mat')\n",
    "# test_data = scipy.io.loadmat('/data/yi/recursive_feature_machines_1/data/test_32x32.mat')\n",
    "\n",
    "# # Extract data (adjust the key names if they differ).\n",
    "# X_train = train_data[\"X\"]   # shape: (32, 32, 3, N)\n",
    "# y_train = train_data[\"y\"]   # shape: (N, 1)\n",
    "# X_test  = test_data[\"X\"]    # shape: (32, 32, 3, N)\n",
    "# y_test  = test_data[\"y\"]    # shape: (N, 1)\n",
    "\n",
    "# # Rearrange and flatten image data:\n",
    "# # Current shape is (32, 32, 3, N); we transpose to (N, 32, 32, 3) then flatten.\n",
    "# X_train = np.transpose(X_train, (3, 0, 1, 2))\n",
    "# X_test  = np.transpose(X_test, (3, 0, 1, 2))\n",
    "# X_train = X_train.reshape(X_train.shape[0], -1)  # shape: (N, 32*32*3)\n",
    "# X_test  = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# # Process labels: flatten if needed.\n",
    "# y_train = y_train.flatten()\n",
    "# y_test  = y_test.flatten()\n",
    "\n",
    "# # Convert data to torch tensors.\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # change dtype if needed\n",
    "# X_test_tensor  = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test_tensor  = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# # Create DataLoaders.\n",
    "# batch_size = 32  # or adjust as desired\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Run the quantum RFM. (iters=2 for a quick demo; adjust iters as needed.)\n",
    "# # M_final, mse = q_rfm(train_loader, test_loader, iters=2, loader=True, classif=True)\n",
    "# K_lap = quantum_laplacian_M(X_train, y_train, bandwidth, M, q_kernel, do_encode=True)\n",
    "# print(\"Laplacian Quantum Kernel Matrix (Dummy Data):\\n\", K_lap)\n",
    "# print(\"Final MSE from q_rfm on .mat data:\", mse)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "# --- Section 1: Laplacian Quantum Kernel with Dummy Data ---\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# -------------------------------\n",
    "# Helper Functions Definitions\n",
    "# -------------------------------\n",
    "\n",
    "def encode_features(X):\n",
    "    \"\"\"\n",
    "    Scales each column of X to [0, 1] then multiplies by pi.\n",
    "    \"\"\"\n",
    "    X = X.copy().astype(np.float64)  # ensure float type to avoid uint8 issues\n",
    "    for j in range(X.shape[1]):\n",
    "        col_min = X[:, j].min()\n",
    "        col_max = X[:, j].max()\n",
    "        if abs(col_max - col_min) < 1e-12:\n",
    "            X[:, j] = 0.0\n",
    "        else:\n",
    "            X[:, j] = (X[:, j] - col_min) / (col_max - col_min)\n",
    "    X *= np.pi\n",
    "    return X\n",
    "\n",
    "def quantum_kernel_matrix(X1, X2, q_kernel, M=None, do_encode=True):\n",
    "    \"\"\"\n",
    "    Evaluates the quantum kernel matrix for inputs X1 and X2.\n",
    "    Applies optional encoding (scaling) and a linear transformation via M.\n",
    "    \"\"\"\n",
    "    # Convert torch.Tensor to NumPy arrays if needed.\n",
    "    if isinstance(X1, torch.Tensor):\n",
    "        X1 = X1.cpu().numpy()\n",
    "    if isinstance(X2, torch.Tensor):\n",
    "        X2 = X2.cpu().numpy()\n",
    "\n",
    "    # Optional encoding: scale data from [0,1] to [0,pi]\n",
    "    if do_encode:\n",
    "        X1 = encode_features(X1)\n",
    "        X2 = encode_features(X2)\n",
    "\n",
    "    # If M is provided, transform the data via its Cholesky factorization.\n",
    "    if M is not None:\n",
    "        sqrtM = np.real_if_close(np.linalg.cholesky(M))\n",
    "        X1 = X1 @ sqrtM\n",
    "        X2 = X2 @ sqrtM\n",
    "\n",
    "    print(\"[DEBUG] Evaluating Quantum Kernel...\")\n",
    "    start_time = time.time()\n",
    "    K = q_kernel.evaluate(x_vec=X1, y_vec=X2)\n",
    "    end_time = time.time()\n",
    "    print(f\"[DEBUG] Kernel evaluated: shape {K.shape}, time {end_time - start_time:.2f} s\")\n",
    "    return K\n",
    "\n",
    "def quantum_laplacian_M(samples, centers, bandwidth, M, q_kernel, do_encode=True):\n",
    "    \"\"\"\n",
    "    Computes a Laplacian-style quantum kernel matrix.\n",
    "    \n",
    "    The quantum kernel is first evaluated (using q_kernel with the M-transformation),\n",
    "    then converted into a distance measure (1 - fidelity), and finally transformed via:\n",
    "        k(x,y) = exp(-gamma * distance(x,y))\n",
    "    where gamma = 1/bandwidth.\n",
    "    \n",
    "    Args:\n",
    "        samples (np.ndarray or torch.Tensor): Input data samples.\n",
    "        centers (np.ndarray or torch.Tensor): Center points.\n",
    "        bandwidth (float): Bandwidth parameter (must be > 0).\n",
    "        M (np.ndarray): Transformation matrix.\n",
    "        q_kernel: A quantum kernel instance (e.g., FidelityQuantumKernel).\n",
    "        do_encode (bool): Whether to encode features (scaling to [0,pi]).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Laplacian quantum kernel matrix.\n",
    "    \"\"\"\n",
    "    assert bandwidth > 0, \"Bandwidth must be greater than 0.\"\n",
    "    \n",
    "    print(\"[DEBUG] Evaluating quantum kernel fidelity matrix...\")\n",
    "    kernel_mat = quantum_kernel_matrix(samples, centers, q_kernel, M=M, do_encode=do_encode)\n",
    "    q_kernel = FidelityQuantumKernel(feature_map=feature_map, enforce_psd=False, max_circuits_per_job=500)\n",
    "    # Convert fidelity to a quantum distance (1 - fidelity)\n",
    "    quantum_distance = 1 - kernel_mat\n",
    "    quantum_distance = np.maximum(quantum_distance, 0)  # ensure non-negative\n",
    "    print(\"[DEBUG] Quantum distance matrix computed (1 - fidelity).\")\n",
    "    \n",
    "    # Apply Laplacian transformation\n",
    "    gamma = 1.0 / bandwidth\n",
    "    print(f\"[DEBUG] Applying Laplacian transformation with gamma = {gamma:.4f}...\")\n",
    "    laplacian_kernel = np.exp(-gamma * quantum_distance)\n",
    "    print(\"[DEBUG] Laplacian quantum kernel matrix computed.\")\n",
    "    return laplacian_kernel\n",
    "\n",
    "# -------------------------------\n",
    "# Dummy Data Demonstration\n",
    "# -------------------------------\n",
    "\n",
    "# Generate dummy data\n",
    "np.random.seed(0)\n",
    "samples = np.random.rand(10, 8)    # 10 samples, 8 features\n",
    "centers = np.random.rand(5, 8)     # 5 centers, 8 features\n",
    "bandwidth = 1.0\n",
    "M = np.eye(8, dtype='float32')     # Identity matrix for transformation\n",
    "\n",
    "# Set up the quantum kernel using Qiskit's FidelityQuantumKernel.\n",
    "feature_dim = 8  # Must match the data feature dimension\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement=\"full\")\n",
    "backend = Aer.get_backend(\"aer_simulator_statevector\")\n",
    "backend.options.num_threads = 60\n",
    "# Disable PSD enforcement to speed up evaluation.\n",
    "q_kernel = FidelityQuantumKernel(feature_map=feature_map, enforce_psd=False, max_circuits_per_job=500)\n",
    "\n",
    "# Compute the Laplacian quantum kernel matrix with dummy data.\n",
    "K_lap = quantum_laplacian_M(samples, centers, bandwidth, M, q_kernel, do_encode=True)\n",
    "print(\"Laplacian Quantum Kernel Matrix (Dummy Data):\\n\", K_lap)\n",
    "\n",
    "\n",
    "# %% [code]\n",
    "# --- Section 2: Running q_rfm with Your .mat Data ---\n",
    "#\n",
    "# Assumptions:\n",
    "#   - Your training and testing data are stored in '/data/yi/recursive_feature_machines_1/data/train_32x32.mat'\n",
    "#     and '/data/yi/recursive_feature_machines_1/data/test_32x32.mat'\n",
    "#   - The .mat files contain:\n",
    "#         X: shape (32, 32, 3, N)   (images)\n",
    "#         y: shape (N, 1)           (labels)\n",
    "#\n",
    "# This section loads the data, preprocesses it (flattening images),\n",
    "# and creates PyTorch DataLoaders to run the quantum RFM.\n",
    "\n",
    "import scipy.io\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Import the q_rfm and get_data functions from your module.\n",
    "from rfm_q import q_rfm, get_data\n",
    "\n",
    "# Load your .mat files.\n",
    "train_data = scipy.io.loadmat('/data/yi/recursive_feature_machines_1/data/train_32x32.mat')\n",
    "test_data = scipy.io.loadmat('/data/yi/recursive_feature_machines_1/data/test_32x32.mat')\n",
    "\n",
    "# Extract data (adjust the key names if they differ).\n",
    "X_train = train_data[\"X\"]   # shape: (32, 32, 3, N)\n",
    "y_train = train_data[\"y\"]   # shape: (N, 1)\n",
    "X_test  = test_data[\"X\"]    # shape: (32, 32, 3, N)\n",
    "y_test  = test_data[\"y\"]    # shape: (N, 1)\n",
    "\n",
    "# Rearrange and flatten image data:\n",
    "# Current shape is (32, 32, 3, N); we transpose to (N, 32, 32, 3) then flatten.\n",
    "X_train = np.transpose(X_train, (3, 0, 1, 2))\n",
    "X_test  = np.transpose(X_test, (3, 0, 1, 2))\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # shape: (N, 32*32*3)\n",
    "X_test  = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Convert image data to float (this is critical to avoid the uint8 error)\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test  = X_test.astype(np.float32)\n",
    "\n",
    "# Process labels: flatten if needed.\n",
    "y_train = y_train.flatten()\n",
    "y_test  = y_test.flatten()\n",
    "\n",
    "# Convert data to torch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # change dtype if needed\n",
    "X_test_tensor  = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders.\n",
    "batch_size = 32  # or adjust as desired\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# After flattening your image data, update M to match the number of features.\n",
    "M = np.eye(X_train.shape[1], dtype='float32')\n",
    "\n",
    "# Example: Compute a Laplacian quantum kernel using X_train as both samples and centers.\n",
    "# (Using y_train as centers is not valid since they are labels.)\n",
    "K_lap_mat = quantum_laplacian_M(X_train, X_train, bandwidth, M, q_kernel, do_encode=True)\n",
    "print(\"Laplacian Quantum Kernel Matrix (MAT Data):\\n\", K_lap_mat)\n",
    "\n",
    "# Optionally, run the quantum RFM.\n",
    "# (Uncomment the following two lines if you wish to run q_rfm.)\n",
    "# M_final, mse = q_rfm(samples, centers, iters=2, loader=True, classif=True)\n",
    "# print(\"Final MSE from q_rfm on .mat data:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "26c245c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 16)\n",
      "(100, 16)\n"
     ]
    }
   ],
   "source": [
    "train_data = scipy.io.loadmat('/data/yi/recursive_feature_machines_1/example_notebooks/data/4x4MNIST_Train&Test/4x4MNIST_Train&Test/MNIST_Train_Nox16.mat')\n",
    "test_data = scipy.io.loadmat('/data/yi/recursive_feature_machines_1/example_notebooks/data/4x4MNIST_Train&Test/4x4MNIST_Train&Test/MNIST_Test_Nox16.mat')\n",
    "\n",
    "X_train = train_data['VV'][:500]\n",
    "X_test = test_data['UU'][:100]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75b26f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Initialize an empty list to store the first column values.\n",
    "y_train = []\n",
    "y_test = []\n",
    "# Specify your CSV file path.\n",
    "csv_file_path1 = '/data/yi/recursive_feature_machines_1/example_notebooks/data/4x4MNIST_Train&Test/mnist_train.csv'\n",
    "csv_file_path2 = '/data/yi/recursive_feature_machines_1/example_notebooks/data/4x4MNIST_Train&Test/mnist_test.csv'\n",
    "# Open the CSV file in read mode.\n",
    "with open(csv_file_path1, newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    \n",
    "    # Iterate over each row in the CSV file.\n",
    "    for row in csvreader:\n",
    "        if row:  # Ensure the row is not empty.\n",
    "            # Append the first column (index 0) to the list.\n",
    "            y_train.append(int(row[0]))\n",
    "\n",
    "with open(csv_file_path2, newline='', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    \n",
    "    # Iterate over each row in the CSV file.\n",
    "    for row in csvreader:\n",
    "        if row:  # Ensure the row is not empty.\n",
    "            # Append the first column (index 0) to the list.\n",
    "            y_test.append(int(row[0]))\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np.eye(num_classes)[y_train[:500]]\n",
    "y_test = np.eye(num_classes)[y_test[:100]]\n",
    "# Final debug print showing all the data collected from the first column.\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Entered q_rfm function...\n",
      "[DEBUG] Initializing Aer backend...\n",
      "[DEBUG] Aer backend initialized successfully\n",
      "[DEBUG] Creating FidelityQuantumKernel...\n",
      "[DEBUG] FidelityQuantumKernel created successfully\n",
      "[DEBUG] Kernel Evaluation Success! Matrix shape: (10, 10)\n",
      "[DEBUG] Loaders provided\n",
      "[DEBUG] X_train shape: torch.Size([500, 16]), y_train shape: torch.Size([500, 10])\n",
      "[DEBUG] X_test shape: torch.Size([100, 16]), y_test shape: torch.Size([100, 10])\n",
      "[DEBUG] Iteration 1/2 started...\n",
      "[DEBUG] Computing K_train...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import hickle\n",
    "from numpy.linalg import solve\n",
    "import time\n",
    "\n",
    "# Qiskit imports for the quantum kernel\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# Dummy get_data function (assumes a DataLoader input)\n",
    "def get_data(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, labels = batch\n",
    "        X_list.append(inputs)\n",
    "        y_list.append(labels)\n",
    "    X = torch.cat(X_list, dim=0)\n",
    "    y = torch.cat(y_list, dim=0)\n",
    "    return X, y\n",
    "\n",
    "# The quantum kernel matrix helper function.\n",
    "def encode_features(X):\n",
    "    \"\"\"Scales each column of X to [0, 1] then multiplies by pi.\"\"\"\n",
    "    X = X.copy().astype(np.float64)  # ensure float type\n",
    "    for j in range(X.shape[1]):\n",
    "        col_min = X[:, j].min()\n",
    "        col_max = X[:, j].max()\n",
    "        if abs(col_max - col_min) < 1e-12:\n",
    "            X[:, j] = 0.0\n",
    "        else:\n",
    "            X[:, j] = (X[:, j] - col_min) / (col_max - col_min)\n",
    "    X *= np.pi\n",
    "    return X\n",
    "\n",
    "def quantum_kernel_matrix(X1, X2, q_kernel, M=None, do_encode=True):\n",
    "    \"\"\"\n",
    "    Evaluates the quantum kernel matrix for inputs X1 and X2.\n",
    "    Applies optional encoding and a linear transformation via M.\n",
    "    \"\"\"\n",
    "    if isinstance(X1, torch.Tensor):\n",
    "        X1 = X1.cpu().numpy()\n",
    "    if isinstance(X2, torch.Tensor):\n",
    "        X2 = X2.cpu().numpy()\n",
    "\n",
    "    if do_encode:\n",
    "        X1 = encode_features(X1)\n",
    "        X2 = encode_features(X2)\n",
    "\n",
    "    if M is not None:\n",
    "        sqrtM = np.real_if_close(np.linalg.cholesky(M))\n",
    "        X1 = X1 @ sqrtM\n",
    "        X2 = X2 @ sqrtM\n",
    "\n",
    "    print(\"[DEBUG] Evaluating Quantum Kernel...\")\n",
    "    start_time = time.time()\n",
    "    K = q_kernel.evaluate(x_vec=X1, y_vec=X2)\n",
    "    end_time = time.time()\n",
    "    print(f\"[DEBUG] Kernel evaluated: shape {K.shape}, time {end_time - start_time:.2f} s\")\n",
    "    return K\n",
    "\n",
    "def quantum_laplacian_M(samples, centers, bandwidth, M, q_kernel, do_encode=True):\n",
    "    \"\"\"\n",
    "    Computes a Laplacian-style quantum kernel matrix.\n",
    "    \"\"\"\n",
    "    assert bandwidth > 0, \"Bandwidth must be > 0.\"\n",
    "    print(\"[DEBUG] Evaluating quantum kernel fidelity matrix...\")\n",
    "    kernel_mat = quantum_kernel_matrix(samples, centers, q_kernel, M=M, do_encode=do_encode)\n",
    "    quantum_distance = 1 - kernel_mat\n",
    "    quantum_distance = np.maximum(quantum_distance, 0)\n",
    "    print(\"[DEBUG] Quantum distance matrix computed (1 - fidelity).\")\n",
    "    gamma = 1.0 / bandwidth\n",
    "    print(f\"[DEBUG] Applying Laplacian transformation with gamma = {gamma:.4f}...\")\n",
    "    laplacian_kernel = np.exp(-gamma * quantum_distance)\n",
    "    print(\"[DEBUG] Laplacian quantum kernel matrix computed.\")\n",
    "    return laplacian_kernel\n",
    "\n",
    "def q_rfm(train_loader, test_loader,\n",
    "          iters=3, name=None, batch_size=2, reg=1e-3,\n",
    "          train_acc=False, loader=True, classif=True):\n",
    "    print(\"[DEBUG] Entered q_rfm function...\")\n",
    "    \"\"\"\n",
    "    Quantum version of the Recursive Feature Machine.\n",
    "    \"\"\"\n",
    "    # Use dummy training data to set the feature dimension\n",
    "    X_train_dummy, _ = get_data(train_loader) if loader else train_loader\n",
    "    feature_dim = X_train_dummy.shape[1]\n",
    "    feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement=\"full\")\n",
    "    print(\"[DEBUG] Initializing Aer backend...\")\n",
    "    backend = Aer.get_backend(\"aer_simulator_statevector\")\n",
    "    print(\"[DEBUG] Aer backend initialized successfully\")\n",
    "    \n",
    "    print(\"[DEBUG] Creating FidelityQuantumKernel...\")\n",
    "    q_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    print(\"[DEBUG] FidelityQuantumKernel created successfully\")\n",
    "    \n",
    "    # Quick test kernel evaluation with small random data\n",
    "    X_test_eval = np.random.rand(10, feature_dim)\n",
    "    K_test_eval = q_kernel.evaluate(x_vec=X_test_eval, y_vec=X_test_eval)\n",
    "    print(\"[DEBUG] Kernel Evaluation Success! Matrix shape:\", K_test_eval.shape)\n",
    "    \n",
    "    L = 10\n",
    "\n",
    "    if loader:\n",
    "        print(\"[DEBUG] Loaders provided\")\n",
    "        X_train, y_train = get_data(train_loader)\n",
    "        X_test, y_test = get_data(test_loader)\n",
    "    else:\n",
    "        print(\"[DEBUG] Loaders not used, loading manually\")\n",
    "        X_train, y_train = train_loader\n",
    "        X_test, y_test = test_loader\n",
    "        X_train = torch.from_numpy(X_train).float()\n",
    "        X_test = torch.from_numpy(X_test).float()\n",
    "        y_train = torch.from_numpy(y_train).float()\n",
    "        y_test = torch.from_numpy(y_test).float()\n",
    "    \n",
    "    print(f\"[DEBUG] X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"[DEBUG] X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    feature_dim = X_train.shape[1]\n",
    "    feature_map.feature_dimension = feature_dim\n",
    "    \n",
    "    n, d = X_train.shape\n",
    "    # Start with an identity matrix M for the recursive update.\n",
    "    M = np.eye(d, dtype='float32')\n",
    "    \n",
    "    for i in range(iters):\n",
    "        print(f\"[DEBUG] Iteration {i+1}/{iters} started...\")\n",
    "        print(\"[DEBUG] Computing K_train...\")\n",
    "        K_train = quantum_kernel_matrix(X_train, X_train, q_kernel)\n",
    "        print(f\"[DEBUG] K_train computed, shape: {K_train.shape}\")\n",
    "        sol = solve(K_train + reg * np.eye(len(K_train)), y_train.numpy()).T\n",
    "        \n",
    "        if train_acc:\n",
    "            preds = (sol @ K_train).T\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_train, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Train Acc: \", count / len(labels))\n",
    "        \n",
    "        K_test = quantum_kernel_matrix(X_train, X_test, q_kernel)\n",
    "        preds = (sol @ K_test).T\n",
    "        mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "        print(\"Round \" + str(i) + \" MSE: \", mse)\n",
    "        \n",
    "        if classif:\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_test, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Acc: \", count / len(labels))\n",
    "        \n",
    "        print(\"[DEBUG] Calling get_grads... (skipped in this dummy demo)\")\n",
    "        # For demonstration, we'll skip the recursive update.\n",
    "        # M = get_grads(X_train, sol, L, torch.from_numpy(M), q_kernel, batch_size=batch_size)\n",
    "        print(\"[DEBUG] get_grads skipped\")\n",
    "    \n",
    "    K_train = quantum_kernel_matrix(X_train, X_train, q_kernel)\n",
    "    print(\"[DEBUG] Solving system of equations...\")\n",
    "    sol = solve(K_train + reg * np.eye(len(K_train)), y_train.numpy()).T\n",
    "    print(\"[DEBUG] System solved\")\n",
    "    K_test = quantum_kernel_matrix(X_train, X_test, q_kernel)\n",
    "    preds = (sol @ K_test).T\n",
    "    mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "    print(\"Final MSE: \", mse)\n",
    "    \n",
    "    if classif:\n",
    "        y_pred = torch.from_numpy(preds)\n",
    "        preds_class = torch.argmax(y_pred, dim=-1)\n",
    "        labels = torch.argmax(y_test, dim=-1)\n",
    "        count = torch.sum(labels == preds_class).numpy()\n",
    "        print(\"Final Acc: \", count / len(labels))\n",
    "    return M, mse\n",
    "\n",
    "# -------------------------------\n",
    "# Create Dummy Data for Classification\n",
    "# -------------------------------\n",
    "\n",
    "# Settings for dummy data:\n",
    "num_train = 100\n",
    "num_test = 20\n",
    "num_features = 8\n",
    "num_classes = 3\n",
    "\n",
    "# # Random input features\n",
    "# X_train_dummy = np.random.rand(num_train, num_features).astype(np.float32)\n",
    "# X_test_dummy = np.random.rand(num_test, num_features).astype(np.float32)\n",
    "\n",
    "# # Random labels: one-hot encoded for 3 classes.\n",
    "# y_train_dummy = np.eye(num_classes)[np.random.randint(0, num_classes, size=num_train)]\n",
    "# y_test_dummy = np.eye(num_classes)[np.random.randint(0, num_classes, size=num_test)]\n",
    "\n",
    "# Convert to torch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders.\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Run q_rfm on dummy data to test MSE and accuracy.\n",
    "M_final, mse_final = q_rfm(train_loader, test_loader, iters=2, loader=True, classif=True, train_acc=True)\n",
    "print(\"Final MSE from q_rfm on 4x4 data:\", mse_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eda77bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Entered q_rfm function...\n",
      "[DEBUG] Initializing Aer backend...\n",
      "[DEBUG] Aer backend initialized successfully\n",
      "[DEBUG] Creating FidelityQuantumKernel...\n",
      "[DEBUG] FidelityQuantumKernel created successfully\n",
      "[DEBUG] Kernel Evaluation Success! Matrix shape: (10, 10)\n",
      "[DEBUG] Loaders provided\n",
      "[DEBUG] X_train shape: torch.Size([100, 8]), y_train shape: torch.Size([100, 3])\n",
      "[DEBUG] X_test shape: torch.Size([20, 8]), y_test shape: torch.Size([20, 3])\n",
      "[DEBUG] Norm of M: 2.8284270763397217, eigenvalues: [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[DEBUG] Iteration 1/2 started...\n",
      "[DEBUG] Computing K_train...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 64.63 s\n",
      "[DEBUG] K_train computed, shape: (100, 100)\n",
      "Round 0 Train Acc:  1.0\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 20), time 25.14 s\n",
      "Round 0 MSE:  0.26082102617157\n",
      "Round 0 Acc:  0.4\n",
      "[DEBUG] Entering get_grads...\n",
      "[DEBUG] Computing quantum kernel matrix for gradients...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 128.66 s\n",
      "[DEBUG] Quantum kernel matrix computed for gradient shape: (100, 100)\n",
      "[DEBUG] Updated M at iteration 1:\n",
      "[[ 0.47690764  0.03122529  0.07626422  0.01716736  0.03829623  0.12816787\n",
      "   0.04226397  0.03063428]\n",
      " [ 0.03122529  0.66819745  0.00816946  0.0046277   0.02481966  0.09161906\n",
      "  -0.02516715 -0.02726902]\n",
      " [ 0.07626422  0.00816946  0.50805354 -0.02551912  0.0206202  -0.09639155\n",
      "   0.05915834 -0.03855585]\n",
      " [ 0.01716736  0.0046277  -0.02551912  0.518162   -0.0792079   0.05362273\n",
      "   0.03856622  0.02228815]\n",
      " [ 0.03829623  0.02481966  0.0206202  -0.0792079   0.48116034  0.00622701\n",
      "   0.03330912  0.05204518]\n",
      " [ 0.12816787  0.09161906 -0.09639155  0.05362273  0.00622701  0.58177686\n",
      "   0.05212613  0.08583617]\n",
      " [ 0.04226397 -0.02516715  0.05915834  0.03856622  0.03330912  0.05212613\n",
      "   0.37327492 -0.01160342]\n",
      " [ 0.03063428 -0.02726902 -0.03855585  0.02228815  0.05204518  0.08583617\n",
      "  -0.01160342  0.3626731 ]]\n",
      "[DEBUG] Norm of M: 1.4828592538833618, eigenvalues: [0.78698343 0.26751027 0.32198718 0.36385372 0.42125037 0.55559087\n",
      " 0.6074577  0.64557236]\n",
      "[DEBUG] Iteration 2/2 started...\n",
      "[DEBUG] Computing K_train...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 64.45 s\n",
      "[DEBUG] K_train computed, shape: (100, 100)\n",
      "Round 1 Train Acc:  1.0\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 20), time 25.29 s\n",
      "Round 1 MSE:  0.24235268364590237\n",
      "Round 1 Acc:  0.7\n",
      "[DEBUG] Entering get_grads...\n",
      "[DEBUG] Computing quantum kernel matrix for gradients...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 129.37 s\n",
      "[DEBUG] Quantum kernel matrix computed for gradient shape: (100, 100)\n",
      "[DEBUG] Updated M at iteration 2:\n",
      "[[ 0.16527906  0.04996439  0.05298089  0.02380004  0.04752456  0.10975752\n",
      "   0.03760947  0.0380262 ]\n",
      " [ 0.04996439  0.30004963  0.01893845  0.03143568  0.01395749  0.1048929\n",
      "   0.00456327 -0.00109093]\n",
      " [ 0.05298089  0.01893845  0.16719438 -0.00863882  0.02798581 -0.04753745\n",
      "   0.03682871 -0.0095356 ]\n",
      " [ 0.02380004  0.03143568 -0.00863882  0.15512574 -0.04907477  0.05516211\n",
      "   0.025303    0.02022116]\n",
      " [ 0.04752456  0.01395749  0.02798581 -0.04907477  0.12855484  0.02501036\n",
      "   0.02624467  0.02879803]\n",
      " [ 0.10975752  0.1048929  -0.04753745  0.05516211  0.02501036  0.2529866\n",
      "   0.04530774  0.07411281]\n",
      " [ 0.03760947  0.00456327  0.03682871  0.025303    0.02624467  0.04530774\n",
      "   0.07875279  0.00932703]\n",
      " [ 0.0380262  -0.00109093 -0.0095356   0.02022116  0.02879803  0.07411281\n",
      "   0.00932703  0.07770249]]\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 63.27 s\n",
      "[DEBUG] Solving system of equations...\n",
      "[DEBUG] System solved\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 20), time 26.69 s\n",
      "Final MSE:  0.24258747956184973\n",
      "Final Acc:  0.4\n",
      "Final MSE from q_rfm on dummy data: 0.24258747956184973\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import hickle\n",
    "from numpy.linalg import solve\n",
    "import time\n",
    "\n",
    "# Qiskit imports for the quantum kernel\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# Dummy get_data function (assumes a DataLoader input)\n",
    "def get_data(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, labels = batch\n",
    "        X_list.append(inputs)\n",
    "        y_list.append(labels)\n",
    "    X = torch.cat(X_list, dim=0)\n",
    "    y = torch.cat(y_list, dim=0)\n",
    "    return X, y\n",
    "\n",
    "# The quantum kernel matrix helper function.\n",
    "def encode_features(X):\n",
    "    \"\"\"Scales each column of X to [0, 1] then multiplies by pi.\"\"\"\n",
    "    X = X.copy().astype(np.float64)  # ensure float type\n",
    "    for j in range(X.shape[1]):\n",
    "        col_min = X[:, j].min()\n",
    "        col_max = X[:, j].max()\n",
    "        if abs(col_max - col_min) < 1e-12:\n",
    "            X[:, j] = 0.0\n",
    "        else:\n",
    "            X[:, j] = (X[:, j] - col_min) / (col_max - col_min)\n",
    "    X *= np.pi\n",
    "    return X\n",
    "\n",
    "def quantum_kernel_matrix(X1, X2, q_kernel, M=None, do_encode=True):\n",
    "    \"\"\"\n",
    "    Evaluates the quantum kernel matrix for inputs X1 and X2.\n",
    "    Applies optional encoding and a linear transformation via M.\n",
    "    \"\"\"\n",
    "    if isinstance(X1, torch.Tensor):\n",
    "        X1 = X1.cpu().numpy()\n",
    "    if isinstance(X2, torch.Tensor):\n",
    "        X2 = X2.cpu().numpy()\n",
    "\n",
    "    if do_encode:\n",
    "        X1 = encode_features(X1)\n",
    "        X2 = encode_features(X2)\n",
    "\n",
    "    if M is not None:\n",
    "        sqrtM = np.real_if_close(np.linalg.cholesky(M))\n",
    "        X1 = X1 @ sqrtM\n",
    "        X2 = X2 @ sqrtM\n",
    "\n",
    "    print(\"[DEBUG] Evaluating Quantum Kernel...\")\n",
    "    start_time = time.time()\n",
    "    K = q_kernel.evaluate(x_vec=X1, y_vec=X2)\n",
    "    end_time = time.time()\n",
    "    print(f\"[DEBUG] Kernel evaluated: shape {K.shape}, time {end_time - start_time:.2f} s\")\n",
    "    return K\n",
    "\n",
    "def quantum_laplacian_M(samples, centers, bandwidth, M, q_kernel, do_encode=True):\n",
    "    \"\"\"\n",
    "    Computes a Laplacian-style quantum kernel matrix.\n",
    "    \"\"\"\n",
    "    assert bandwidth > 0, \"Bandwidth must be > 0.\"\n",
    "    print(\"[DEBUG] Evaluating quantum kernel fidelity matrix...\")\n",
    "    kernel_mat = quantum_kernel_matrix(samples, centers, q_kernel, M=M, do_encode=do_encode)\n",
    "    quantum_distance = 1 - kernel_mat\n",
    "    quantum_distance = np.maximum(quantum_distance, 0)\n",
    "    print(\"[DEBUG] Quantum distance matrix computed (1 - fidelity).\")\n",
    "    gamma = 1.0 / bandwidth\n",
    "    print(f\"[DEBUG] Applying Laplacian transformation with gamma = {gamma:.4f}...\")\n",
    "    laplacian_kernel = np.exp(-gamma * quantum_distance)\n",
    "    print(\"[DEBUG] Laplacian quantum kernel matrix computed.\")\n",
    "    return laplacian_kernel\n",
    "\n",
    "def get_grads(X, sol, L, M, q_kernel, batch_size=2, do_encode=True):\n",
    "    \"\"\"\n",
    "    Quantum-based gradient update that uses the quantum kernel (with M-transformation)\n",
    "    in place of a classical kernel.\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] Entering get_grads...\")\n",
    "    if isinstance(X, torch.Tensor):\n",
    "        X = X.cpu().numpy()\n",
    "    num_samples = min(len(X), 1000)\n",
    "    indices = np.random.choice(len(X), size=num_samples, replace=False)\n",
    "    x = X[indices, :]\n",
    "\n",
    "    print(\"[DEBUG] Computing quantum kernel matrix for gradients...\")\n",
    "    K = quantum_kernel_matrix(X, x, q_kernel, M=M, do_encode=do_encode)\n",
    "    print(\"[DEBUG] Quantum kernel matrix computed for gradient shape:\", K.shape)\n",
    "\n",
    "    a1 = torch.from_numpy(sol.T).float()\n",
    "    n, d = X.shape\n",
    "    n, c = a1.shape\n",
    "    m, d = x.shape\n",
    "\n",
    "    a1 = a1.reshape(n, c, 1)\n",
    "    X1 = torch.from_numpy(X).float() @ torch.from_numpy(M).float()\n",
    "    X1 = X1.reshape(n, 1, d)\n",
    "    step1 = a1 @ X1\n",
    "    del a1, X1\n",
    "    step1 = step1.reshape(-1, c * d)\n",
    "\n",
    "    step2 = torch.from_numpy(K).float().T @ step1\n",
    "    del step1\n",
    "    step2 = step2.reshape(-1, c, d)\n",
    "\n",
    "    a2 = torch.from_numpy(sol).float()\n",
    "    step3 = (a2 @ torch.from_numpy(K).float()).T\n",
    "    del K, a2\n",
    "    step3 = step3.reshape(m, c, 1)\n",
    "    x1 = torch.from_numpy(x).float() @ torch.from_numpy(M).float()\n",
    "    x1 = x1.reshape(m, 1, d)\n",
    "    step3 = step3 @ x1\n",
    "\n",
    "    G = (step2 - step3) * -1.0 / L\n",
    "\n",
    "    M_new = 0.0\n",
    "    batches = torch.split(G, batch_size)\n",
    "    for i in range(len(batches)):\n",
    "        grad = batches[i]\n",
    "        gradT = torch.transpose(grad, 1, 2)\n",
    "        M_new += torch.sum(gradT @ grad, dim=0).cpu()\n",
    "        del grad, gradT\n",
    "    M_new /= len(G)\n",
    "    M_new = M_new.numpy()\n",
    "    return M_new\n",
    "\n",
    "def q_rfm(train_loader, test_loader,\n",
    "          iters=3, name=None, batch_size=2, reg=1e-3,\n",
    "          train_acc=False, loader=True, classif=True):\n",
    "    print(\"[DEBUG] Entered q_rfm function...\")\n",
    "    \"\"\"\n",
    "    Quantum version of the Recursive Feature Machine.\n",
    "    \"\"\"\n",
    "    X_train_dummy, _ = get_data(train_loader) if loader else train_loader\n",
    "    feature_dim = X_train_dummy.shape[1]\n",
    "    feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement=\"full\")\n",
    "    print(\"[DEBUG] Initializing Aer backend...\")\n",
    "    backend = Aer.get_backend(\"aer_simulator_statevector\")\n",
    "    backend.options.num_threads = 60\n",
    "    print(\"[DEBUG] Aer backend initialized successfully\")\n",
    "    \n",
    "    print(\"[DEBUG] Creating FidelityQuantumKernel...\")\n",
    "    q_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    print(\"[DEBUG] FidelityQuantumKernel created successfully\")\n",
    "    \n",
    "    X_test_eval = np.random.rand(10, feature_dim)\n",
    "    K_test_eval = q_kernel.evaluate(x_vec=X_test_eval, y_vec=X_test_eval)\n",
    "    print(\"[DEBUG] Kernel Evaluation Success! Matrix shape:\", K_test_eval.shape)\n",
    "    \n",
    "    L = 0.1\n",
    "\n",
    "    if loader:\n",
    "        print(\"[DEBUG] Loaders provided\")\n",
    "        X_train, y_train = get_data(train_loader)\n",
    "        X_test, y_test = get_data(test_loader)\n",
    "    else:\n",
    "        print(\"[DEBUG] Loaders not used, loading manually\")\n",
    "        X_train, y_train = train_loader\n",
    "        X_test, y_test = test_loader\n",
    "        X_train = torch.from_numpy(X_train).float()\n",
    "        X_test = torch.from_numpy(X_test).float()\n",
    "        y_train = torch.from_numpy(y_train).float()\n",
    "        y_test = torch.from_numpy(y_test).float()\n",
    "    \n",
    "    print(f\"[DEBUG] X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"[DEBUG] X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    feature_dim = X_train.shape[1]\n",
    "    feature_map.feature_dimension = feature_dim\n",
    "    \n",
    "    n, d = X_train.shape\n",
    "    M = np.eye(d, dtype='float32')\n",
    "    \n",
    "    for i in range(iters):\n",
    "        eigvals = np.linalg.eigvals(M)\n",
    "        print(f\"[DEBUG] Norm of M: {np.linalg.norm(M)}, eigenvalues: {eigvals}\")\n",
    "\n",
    "        print(f\"[DEBUG] Iteration {i+1}/{iters} started...\")\n",
    "        print(\"[DEBUG] Computing K_train...\")\n",
    "        K_train = quantum_kernel_matrix(X_train, X_train, q_kernel, M=M)\n",
    "        print(f\"[DEBUG] K_train computed, shape: {K_train.shape}\")\n",
    "        sol = solve(K_train + reg * np.eye(len(K_train)), y_train.numpy()).T\n",
    "        \n",
    "        if train_acc:\n",
    "            preds = (sol @ K_train).T\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_train, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Train Acc: \", count / len(labels))\n",
    "        \n",
    "        K_test = quantum_kernel_matrix(X_train, X_test, q_kernel, M=M)\n",
    "        preds = (sol @ K_test).T\n",
    "        mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "        print(\"Round \" + str(i) + \" MSE: \", mse)\n",
    "        \n",
    "        if classif:\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_test, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Acc: \", count / len(labels))\n",
    "        \n",
    "        M = get_grads(X_train, sol, L, M, q_kernel, batch_size=batch_size, do_encode=True)\n",
    "        print(f\"[DEBUG] Updated M at iteration {i+1}:\\n{M}\")\n",
    "    \n",
    "    K_train = quantum_kernel_matrix(X_train, X_train, q_kernel, M=M)\n",
    "    print(\"[DEBUG] Solving system of equations...\")\n",
    "    sol = solve(K_train + reg * np.eye(len(K_train)), y_train.numpy()).T\n",
    "    print(\"[DEBUG] System solved\")\n",
    "    K_test = quantum_kernel_matrix(X_train, X_test, q_kernel, M=M)\n",
    "    preds = (sol @ K_test).T\n",
    "    mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "    print(\"Final MSE: \", mse)\n",
    "    \n",
    "    if classif:\n",
    "        y_pred = torch.from_numpy(preds)\n",
    "        preds_class = torch.argmax(y_pred, dim=-1)\n",
    "        labels = torch.argmax(y_test, dim=-1)\n",
    "        count = torch.sum(labels == preds_class).numpy()\n",
    "        print(\"Final Acc: \", count / len(labels))\n",
    "        \n",
    "    return M, mse\n",
    "\n",
    "# -------------------------------\n",
    "# Create Dummy Data for Classification\n",
    "# -------------------------------\n",
    "\n",
    "num_train = 100\n",
    "num_test = 20\n",
    "num_features = 8\n",
    "num_classes = 3\n",
    "\n",
    "X_train_dummy = np.random.rand(num_train, num_features).astype(np.float32)\n",
    "X_test_dummy = np.random.rand(num_test, num_features).astype(np.float32)\n",
    "y_train_dummy = np.eye(num_classes)[np.random.randint(0, num_classes, size=num_train)]\n",
    "y_test_dummy = np.eye(num_classes)[np.random.randint(0, num_classes, size=num_test)]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_dummy, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_dummy, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_dummy, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_dummy, dtype=torch.float32)\n",
    "\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "M_final, mse_final = q_rfm(train_loader, test_loader, iters=2, loader=True, classif=True, train_acc=True)\n",
    "print(\"Final MSE from q_rfm on dummy data:\", mse_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47b8ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Entered q_rfm function...\n",
      "[DEBUG] Initializing Aer backend...\n",
      "[DEBUG] Aer backend initialized successfully\n",
      "[DEBUG] Creating FidelityQuantumKernel...\n",
      "[DEBUG] FidelityQuantumKernel created successfully\n",
      "[DEBUG] Kernel Evaluation Success! Matrix shape: (10, 10)\n",
      "[DEBUG] Loaders provided\n",
      "[DEBUG] X_train shape: torch.Size([100, 8]), y_train shape: torch.Size([100, 3])\n",
      "[DEBUG] X_test shape: torch.Size([20, 8]), y_test shape: torch.Size([20, 3])\n",
      "[DEBUG] Iteration 1/2 started...\n",
      "[DEBUG] Computing K_train...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 425.89 s\n",
      "[DEBUG] K_train computed, shape: (100, 100)\n",
      "Round 0 Train Acc:  1.0\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 20), time 33.13 s\n",
      "Round 0 MSE:  0.2640631905913511\n",
      "Round 0 Acc:  0.45\n",
      "[DEBUG] Entering get_grads...\n",
      "[DEBUG] Computing quantum kernel matrix for gradients...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 139.72 s\n",
      "[DEBUG] Quantum kernel matrix computed for gradient shape: (100, 100)\n",
      "[DEBUG] Updated M at iteration 1:\n",
      "[[ 0.5642495  -0.0550776   0.01013751 -0.01846105  0.02079228  0.0578693\n",
      "  -0.0514861  -0.04779727]\n",
      " [-0.0550776   0.48274335 -0.01491487  0.07664666  0.06422226  0.03278028\n",
      "  -0.01811141  0.03467787]\n",
      " [ 0.01013751 -0.01491487  0.43101588 -0.00551844  0.0119594  -0.00535067\n",
      "   0.05263158 -0.0506582 ]\n",
      " [-0.01846105  0.07664666 -0.00551844  0.46930486  0.09388906  0.01739492\n",
      "   0.00663278  0.04175845]\n",
      " [ 0.02079228  0.06422226  0.0119594   0.09388906  0.6172468   0.08500095\n",
      "   0.08102801  0.08394558]\n",
      " [ 0.0578693   0.03278028 -0.00535067  0.01739492  0.08500095  0.4652488\n",
      "   0.01630781  0.04086864]\n",
      " [-0.0514861  -0.01811141  0.05263158  0.00663278  0.08102801  0.01630781\n",
      "   0.44532964  0.01433917]\n",
      " [-0.04779727  0.03467787 -0.0506582   0.04175845  0.08394558  0.04086864\n",
      "   0.01433917  0.48778307]]\n",
      "[DEBUG] Iteration 2/2 started...\n",
      "[DEBUG] Computing K_train...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 63.65 s\n",
      "[DEBUG] K_train computed, shape: (100, 100)\n",
      "Round 1 Train Acc:  1.0\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 20), time 26.55 s\n",
      "Round 1 MSE:  0.25477611701872427\n",
      "Round 1 Acc:  0.45\n",
      "[DEBUG] Entering get_grads...\n",
      "[DEBUG] Computing quantum kernel matrix for gradients...\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 128.85 s\n",
      "[DEBUG] Quantum kernel matrix computed for gradient shape: (100, 100)\n",
      "[DEBUG] Updated M at iteration 2:\n",
      "[[ 0.18729004 -0.03130426  0.00569798  0.00743162  0.03241635  0.05368822\n",
      "  -0.02594026 -0.0154894 ]\n",
      " [-0.03130426  0.14455059 -0.00363869  0.06549313  0.05958988  0.01700946\n",
      "  -0.00675528  0.02851364]\n",
      " [ 0.00569798 -0.00363869  0.10663807 -0.00043069  0.03044097  0.00375988\n",
      "   0.03879581 -0.03678028]\n",
      " [ 0.00743162  0.06549313 -0.00043069  0.13969134  0.08901221  0.02768602\n",
      "   0.00361349  0.03388722]\n",
      " [ 0.03241635  0.05958988  0.03044097  0.08901221  0.2823819   0.09487524\n",
      "   0.0796929   0.07671032]\n",
      " [ 0.05368822  0.01700946  0.00375988  0.02768602  0.09487524  0.13211958\n",
      "   0.03091992  0.04209049]\n",
      " [-0.02594026 -0.00675528  0.03879581  0.00361349  0.0796929   0.03091992\n",
      "   0.1304638   0.01864536]\n",
      " [-0.0154894   0.02851364 -0.03678028  0.03388722  0.07671032  0.04209049\n",
      "   0.01864536  0.1446891 ]]\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 100), time 64.43 s\n",
      "[DEBUG] Solving system of equations...\n",
      "[DEBUG] System solved\n",
      "[DEBUG] Evaluating Quantum Kernel...\n",
      "[DEBUG] Kernel evaluated: shape (100, 20), time 26.08 s\n",
      "Final MSE:  0.25165778883387635\n",
      "Final Acc:  0.2\n",
      "Final MSE from q_rfm on dummy data: 0.25165778883387635\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import hickle\n",
    "from numpy.linalg import solve\n",
    "import time\n",
    "\n",
    "# Qiskit imports for the quantum kernel\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "# Dummy get_data function (assumes a DataLoader input)\n",
    "def get_data(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for batch in loader:\n",
    "        inputs, labels = batch\n",
    "        X_list.append(inputs)\n",
    "        y_list.append(labels)\n",
    "    X = torch.cat(X_list, dim=0)\n",
    "    y = torch.cat(y_list, dim=0)\n",
    "    return X, y\n",
    "\n",
    "# The quantum kernel matrix helper function.\n",
    "def encode_features(X):\n",
    "    \"\"\"Scales each column of X to [0, 1] then multiplies by pi.\"\"\"\n",
    "    X = X.copy().astype(np.float64)  # ensure float type\n",
    "    for j in range(X.shape[1]):\n",
    "        col_min = X[:, j].min()\n",
    "        col_max = X[:, j].max()\n",
    "        if abs(col_max - col_min) < 1e-12:\n",
    "            X[:, j] = 0.0\n",
    "        else:\n",
    "            X[:, j] = (X[:, j] - col_min) / (col_max - col_min)\n",
    "    X *= np.pi\n",
    "    return X\n",
    "\n",
    "def quantum_kernel_matrix(X1, X2, q_kernel, M=None, do_encode=True):\n",
    "    \"\"\"\n",
    "    Evaluates the quantum kernel matrix for inputs X1 and X2.\n",
    "    Applies optional encoding and a linear transformation via M.\n",
    "    \"\"\"\n",
    "    if isinstance(X1, torch.Tensor):\n",
    "        X1 = X1.cpu().numpy()\n",
    "    if isinstance(X2, torch.Tensor):\n",
    "        X2 = X2.cpu().numpy()\n",
    "\n",
    "    if do_encode:\n",
    "        X1 = encode_features(X1)\n",
    "        X2 = encode_features(X2)\n",
    "\n",
    "    if M is not None:\n",
    "        sqrtM = np.real_if_close(np.linalg.cholesky(M))\n",
    "        X1 = X1 @ sqrtM\n",
    "        X2 = X2 @ sqrtM\n",
    "\n",
    "    print(\"[DEBUG] Evaluating Quantum Kernel...\")\n",
    "    start_time = time.time()\n",
    "    K = q_kernel.evaluate(x_vec=X1, y_vec=X2)\n",
    "    end_time = time.time()\n",
    "    print(f\"[DEBUG] Kernel evaluated: shape {K.shape}, time {end_time - start_time:.2f} s\")\n",
    "    return K\n",
    "\n",
    "def quantum_laplacian_M(samples, centers, bandwidth, M, q_kernel, do_encode=True):\n",
    "    \"\"\"\n",
    "    Computes a Laplacian-style quantum kernel matrix.\n",
    "    \"\"\"\n",
    "    assert bandwidth > 0, \"Bandwidth must be > 0.\"\n",
    "    print(\"[DEBUG] Evaluating quantum kernel fidelity matrix...\")\n",
    "    kernel_mat = quantum_kernel_matrix(samples, centers, q_kernel, M=M, do_encode=do_encode)\n",
    "    quantum_distance = 1 - kernel_mat\n",
    "    quantum_distance = np.maximum(quantum_distance, 0)\n",
    "    print(\"[DEBUG] Quantum distance matrix computed (1 - fidelity).\")\n",
    "    gamma = 1.0 / bandwidth\n",
    "    print(f\"[DEBUG] Applying Laplacian transformation with gamma = {gamma:.4f}...\")\n",
    "    laplacian_kernel = np.exp(-gamma * quantum_distance)\n",
    "    print(\"[DEBUG] Laplacian quantum kernel matrix computed.\")\n",
    "    return laplacian_kernel\n",
    "\n",
    "def get_grads(X, sol, L, M, q_kernel, batch_size=2, do_encode=True):\n",
    "    \"\"\"\n",
    "    Quantum-based gradient update that uses the quantum kernel (with M-transformation)\n",
    "    in place of a classical kernel.\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] Entering get_grads...\")\n",
    "    if isinstance(X, torch.Tensor):\n",
    "        X = X.cpu().numpy()\n",
    "    num_samples = min(len(X), 1000)\n",
    "    indices = np.random.choice(len(X), size=num_samples, replace=False)\n",
    "    x = X[indices, :]\n",
    "\n",
    "    print(\"[DEBUG] Computing quantum kernel matrix for gradients...\")\n",
    "    K = quantum_kernel_matrix(X, x, q_kernel, M=M, do_encode=do_encode)\n",
    "    print(\"[DEBUG] Quantum kernel matrix computed for gradient shape:\", K.shape)\n",
    "\n",
    "    a1 = torch.from_numpy(sol.T).float()\n",
    "    n, d = X.shape\n",
    "    n, c = a1.shape\n",
    "    m, d = x.shape\n",
    "\n",
    "    a1 = a1.reshape(n, c, 1)\n",
    "    X1 = torch.from_numpy(X).float() @ torch.from_numpy(M).float()\n",
    "    X1 = X1.reshape(n, 1, d)\n",
    "    step1 = a1 @ X1\n",
    "    del a1, X1\n",
    "    step1 = step1.reshape(-1, c * d)\n",
    "\n",
    "    step2 = torch.from_numpy(K).float().T @ step1\n",
    "    del step1\n",
    "    step2 = step2.reshape(-1, c, d)\n",
    "\n",
    "    a2 = torch.from_numpy(sol).float()\n",
    "    step3 = (a2 @ torch.from_numpy(K).float()).T\n",
    "    del K, a2\n",
    "    step3 = step3.reshape(m, c, 1)\n",
    "    x1 = torch.from_numpy(x).float() @ torch.from_numpy(M).float()\n",
    "    x1 = x1.reshape(m, 1, d)\n",
    "    step3 = step3 @ x1\n",
    "\n",
    "    G = (step2 - step3) * -1.0 / L\n",
    "\n",
    "    M_new = 0.0\n",
    "    batches = torch.split(G, batch_size)\n",
    "    for i in range(len(batches)):\n",
    "        grad = batches[i]\n",
    "        gradT = torch.transpose(grad, 1, 2)\n",
    "        M_new += torch.sum(gradT @ grad, dim=0).cpu()\n",
    "        del grad, gradT\n",
    "    M_new /= len(G)\n",
    "    M_new = M_new.numpy()\n",
    "    return M_new\n",
    "\n",
    "def q_rfm(train_loader, test_loader,\n",
    "          iters=3, name=None, batch_size=2, reg=1e-3,\n",
    "          train_acc=False, loader=True, classif=True):\n",
    "    print(\"[DEBUG] Entered q_rfm function...\")\n",
    "    \"\"\"\n",
    "    Quantum version of the Recursive Feature Machine.\n",
    "    \"\"\"\n",
    "    X_train_dummy, _ = get_data(train_loader) if loader else train_loader\n",
    "    feature_dim = X_train_dummy.shape[1]\n",
    "    feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=1, entanglement=\"full\")\n",
    "    print(\"[DEBUG] Initializing Aer backend...\")\n",
    "    backend = Aer.get_backend(\"aer_simulator_statevector\")\n",
    "    backend.options.num_threads = 60\n",
    "    print(\"[DEBUG] Aer backend initialized successfully\")\n",
    "    \n",
    "    print(\"[DEBUG] Creating FidelityQuantumKernel...\")\n",
    "    q_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    print(\"[DEBUG] FidelityQuantumKernel created successfully\")\n",
    "    \n",
    "    X_test_eval = np.random.rand(10, feature_dim)\n",
    "    K_test_eval = q_kernel.evaluate(x_vec=X_test_eval, y_vec=X_test_eval)\n",
    "    print(\"[DEBUG] Kernel Evaluation Success! Matrix shape:\", K_test_eval.shape)\n",
    "    \n",
    "    L = 0.1\n",
    "\n",
    "    if loader:\n",
    "        print(\"[DEBUG] Loaders provided\")\n",
    "        X_train, y_train = get_data(train_loader)\n",
    "        X_test, y_test = get_data(test_loader)\n",
    "    else:\n",
    "        print(\"[DEBUG] Loaders not used, loading manually\")\n",
    "        X_train, y_train = train_loader\n",
    "        X_test, y_test = test_loader\n",
    "        X_train = torch.from_numpy(X_train).float()\n",
    "        X_test = torch.from_numpy(X_test).float()\n",
    "        y_train = torch.from_numpy(y_train).float()\n",
    "        y_test = torch.from_numpy(y_test).float()\n",
    "    \n",
    "    print(f\"[DEBUG] X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"[DEBUG] X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    feature_dim = X_train.shape[1]\n",
    "    feature_map.feature_dimension = feature_dim\n",
    "    \n",
    "    n, d = X_train.shape\n",
    "    M = np.eye(d, dtype='float32')\n",
    "    \n",
    "    for i in range(iters):\n",
    "        print(f\"[DEBUG] Iteration {i+1}/{iters} started...\")\n",
    "        print(\"[DEBUG] Computing K_train...\")\n",
    "        K_train = quantum_kernel_matrix(X_train, X_train, q_kernel, M=M)\n",
    "        print(f\"[DEBUG] K_train computed, shape: {K_train.shape}\")\n",
    "        sol = solve(K_train + reg * np.eye(len(K_train)), y_train.numpy()).T\n",
    "        \n",
    "        if train_acc:\n",
    "            preds = (sol @ K_train).T\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_train, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Train Acc: \", count / len(labels))\n",
    "        \n",
    "        K_test = quantum_kernel_matrix(X_train, X_test, q_kernel, M=M)\n",
    "        preds = (sol @ K_test).T\n",
    "        mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "        print(\"Round \" + str(i) + \" MSE: \", mse)\n",
    "        \n",
    "        if classif:\n",
    "            y_pred = torch.from_numpy(preds)\n",
    "            preds_class = torch.argmax(y_pred, dim=-1)\n",
    "            labels = torch.argmax(y_test, dim=-1)\n",
    "            count = torch.sum(labels == preds_class).numpy()\n",
    "            print(\"Round \" + str(i) + \" Acc: \", count / len(labels))\n",
    "        \n",
    "        M = get_grads(X_train, sol, L, M, q_kernel, batch_size=batch_size, do_encode=True)\n",
    "        print(f\"[DEBUG] Updated M at iteration {i+1}:\\n{M}\")\n",
    "    \n",
    "    K_train = quantum_kernel_matrix(X_train, X_train, q_kernel, M=M)\n",
    "    print(\"[DEBUG] Solving system of equations...\")\n",
    "    sol = solve(K_train + reg * np.eye(len(K_train)), y_train.numpy()).T\n",
    "    print(\"[DEBUG] System solved\")\n",
    "    K_test = quantum_kernel_matrix(X_train, X_test, q_kernel, M=M)\n",
    "    preds = (sol @ K_test).T\n",
    "    mse = np.mean(np.square(preds - y_test.numpy()))\n",
    "    print(\"Final MSE: \", mse)\n",
    "    \n",
    "    if classif:\n",
    "        y_pred = torch.from_numpy(preds)\n",
    "        preds_class = torch.argmax(y_pred, dim=-1)\n",
    "        labels = torch.argmax(y_test, dim=-1)\n",
    "        count = torch.sum(labels == preds_class).numpy()\n",
    "        print(\"Final Acc: \", count / len(labels))\n",
    "    return M, mse\n",
    "\n",
    "# -------------------------------\n",
    "# Create Dummy Data for Classification\n",
    "# -------------------------------\n",
    "\n",
    "num_train = 100\n",
    "num_test = 20\n",
    "num_features = 8\n",
    "num_classes = 3\n",
    "\n",
    "X_train_dummy = np.random.rand(num_train, num_features).astype(np.float32)\n",
    "X_test_dummy = np.random.rand(num_test, num_features).astype(np.float32)\n",
    "y_train_dummy = np.eye(num_classes)[np.random.randint(0, num_classes, size=num_train)]\n",
    "y_test_dummy = np.eye(num_classes)[np.random.randint(0, num_classes, size=num_test)]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_dummy, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_dummy, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_dummy, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_dummy, dtype=torch.float32)\n",
    "\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "M_final, mse_final = q_rfm(train_loader, test_loader, iters=2, loader=True, classif=True, train_acc=True)\n",
    "print(\"Final MSE from q_rfm on dummy data:\", mse_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0e597da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Entered q_rfm function...\n",
      "[DEBUG] X_train shape: torch.Size([500, 3072]) y_train shape: torch.Size([500, 10])\n",
      "[DEBUG] X_test shape: torch.Size([500, 3072]) y_test shape: torch.Size([500, 10])\n",
      "3072\n",
      "[DEBUG] Iteration 1/2\n",
      "[DEBUG] Evaluating Quantum Kernel...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrfm_q\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m q_rfm, get_data\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# ... prepare your train_loader and test_loader (or use your PCA reduced data)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m M, mse \u001b[38;5;241m=\u001b[39m \u001b[43mq_rfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassif\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recursive_feature_machines_1/example_notebooks/rfm_q.py:957\u001b[0m, in \u001b[0;36mq_rfm\u001b[0;34m(train_loader, test_loader, iters, name, batch_size, reg, train_acc, loader, classif)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;66;03m# Compute quantum kernel on training data (with data transformed by sqrt(M))\u001b[39;00m\n\u001b[0;32m--> 957\u001b[0m K_train \u001b[38;5;241m=\u001b[39m \u001b[43mquantum_kernel_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_encode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m sol \u001b[38;5;241m=\u001b[39m solve(K_train \u001b[38;5;241m+\u001b[39m reg \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mlen\u001b[39m(K_train)), y_train\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    960\u001b[0m \u001b[38;5;66;03m# Optionally compute training accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/recursive_feature_machines_1/example_notebooks/rfm_q.py:818\u001b[0m, in \u001b[0;36mquantum_kernel_matrix\u001b[0;34m(X1, X2, q_kernel, M, do_encode)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Evaluating Quantum Kernel...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    817\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 818\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43mq_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Quantum Kernel evaluated successfully! Shape =\u001b[39m\u001b[38;5;124m\"\u001b[39m, K\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/rfm_env/lib/python3.8/site-packages/qiskit_machine_learning/kernels/fidelity_quantum_kernel.py:113\u001b[0m, in \u001b[0;36mFidelityQuantumKernel.evaluate\u001b[0;34m(self, x_vec, y_vec)\u001b[0m\n\u001b[1;32m    110\u001b[0m kernel_shape \u001b[38;5;241m=\u001b[39m (x_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], y_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_symmetric:\n\u001b[0;32m--> 113\u001b[0m     left_parameters, right_parameters, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_symmetric_parameterization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_symmetric_kernel_matrix(\n\u001b[1;32m    115\u001b[0m         kernel_shape, left_parameters, right_parameters, indices\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rfm_env/lib/python3.8/site-packages/qiskit_machine_learning/kernels/fidelity_quantum_kernel.py:167\u001b[0m, in \u001b[0;36mFidelityQuantumKernel._get_symmetric_parameterization\u001b[0;34m(self, x_vec)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    166\u001b[0m         left_parameters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((left_parameters, x_i))\n\u001b[0;32m--> 167\u001b[0m         right_parameters \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m         indices\u001b[38;5;241m.\u001b[39mappend((i, i \u001b[38;5;241m+\u001b[39m j))\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left_parameters, right_parameters, indices\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/rfm_env/lib/python3.8/site-packages/numpy/core/shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rfm_q import q_rfm, get_data\n",
    "# ... prepare your train_loader and test_loader (or use your PCA reduced data)\n",
    "M, mse = q_rfm(train_loader, test_loader, iters=2, loader=True, classif=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.kernels import BaseKernel\n",
    "from qiskit_aer import AerSimulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run rfm\n",
    "M, _ = q_rfm(train_loader, test_loader, iters=2, loader=True, classif=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02aed4",
   "metadata": {},
   "source": [
    "We have run three steps of RFM (the first iterate is the original laplace kernel), returning the M matrix of the final iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a730cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize M matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66b0f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,2,figsize=(10, 3))\n",
    "axarr[0].axes.xaxis.set_ticklabels([])\n",
    "axarr[0].axes.yaxis.set_ticklabels([])\n",
    "axarr[1].axes.xaxis.set_ticklabels([])\n",
    "axarr[1].axes.yaxis.set_ticklabels([])\n",
    "\n",
    "pcm = axarr[0].imshow(np.mean(np.diag(M).reshape(3,32,32),axis=0),cmap='cividis')\n",
    "axarr[0].set_title(\"M matrix diagonal\")\n",
    "f.colorbar(mappable=pcm, ax=axarr[0], shrink=0.8,location=\"left\")\n",
    "axarr[1].imshow(torch.moveaxis(trainset0[3][0],0,2))\n",
    "axarr[1].set_title(\"Sample Image\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8bb8a2",
   "metadata": {},
   "source": [
    "Here we plot the diagonal (averaged across channels) of the M matrix to see which coordinates are being highlighted by RFM. The center of the image is highlighted (where the digits appear). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d553b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
